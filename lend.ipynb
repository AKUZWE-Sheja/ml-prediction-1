{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "693a1a67-7875-4e26-9247-4fb4dea88571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and inspecting data...\n",
      "\n",
      "=== First 5 Rows ===\n",
      "       Loan_ID loan_status  Principal  terms effective_date   due_date  \\\n",
      "0  xqd20166231     PAIDOFF       1000     30       9/8/2016  10/7/2016   \n",
      "1  xqd20168902     PAIDOFF       1000     30       9/8/2016  10/7/2016   \n",
      "2  xqd20160003     PAIDOFF       1000     30       9/8/2016  10/7/2016   \n",
      "3  xqd20160004     PAIDOFF       1000     15       9/8/2016  9/22/2016   \n",
      "4  xqd20160005     PAIDOFF       1000     30       9/9/2016  10/8/2016   \n",
      "\n",
      "     paid_off_time  past_due_days  age             education  Gender  \n",
      "0  9/14/2016 19:31            NaN   45  High_School_or_Below    male  \n",
      "1   10/7/2016 9:00            NaN   50              Bachelor  female  \n",
      "2  9/25/2016 16:58            NaN   33              Bachelor  female  \n",
      "3  9/22/2016 20:00            NaN   27               College    male  \n",
      "4  9/23/2016 21:36            NaN   28               College  female  \n",
      "\n",
      "=== Dataset Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Loan_ID         500 non-null    object \n",
      " 1   loan_status     500 non-null    object \n",
      " 2   Principal       500 non-null    int64  \n",
      " 3   terms           500 non-null    int64  \n",
      " 4   effective_date  500 non-null    object \n",
      " 5   due_date        500 non-null    object \n",
      " 6   paid_off_time   400 non-null    object \n",
      " 7   past_due_days   200 non-null    float64\n",
      " 8   age             500 non-null    int64  \n",
      " 9   education       500 non-null    object \n",
      " 10  Gender          500 non-null    object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 43.1+ KB\n",
      "None\n",
      "\n",
      "=== Missing Values ===\n",
      "Loan_ID             0\n",
      "loan_status         0\n",
      "Principal           0\n",
      "terms               0\n",
      "effective_date      0\n",
      "due_date            0\n",
      "paid_off_time     100\n",
      "past_due_days     300\n",
      "age                 0\n",
      "education           0\n",
      "Gender              0\n",
      "dtype: int64\n",
      "\n",
      "Cleaning data...\n",
      "\n",
      "Engineering features...\n",
      "\n",
      "Analyzing correlations...\n",
      "\n",
      "=== Correlation with loan_status ===\n",
      "loan_status      1.000000\n",
      "Gender           0.076911\n",
      "education        0.025100\n",
      "age              0.018939\n",
      "Principal       -0.087235\n",
      "terms           -0.108395\n",
      "past_due_days   -0.689415\n",
      "Name: loan_status, dtype: float64\n",
      "\n",
      "Preparing data for modeling...\n",
      "\n",
      "Class distribution:\n",
      "loan_status\n",
      "1    0.6\n",
      "0    0.4\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class weights: {0: np.float64(1.25), 1: np.float64(0.8333333333333334)}\n",
      "\n",
      "Selecting best features...\n",
      "\n",
      "Feature importance scores:\n",
      "     Feature     Score\n",
      "1      terms  2.759693\n",
      "4     Gender  2.205816\n",
      "0  Principal  2.157648\n",
      "3  education  0.811478\n",
      "2        age  0.403037\n",
      "\n",
      "Training and evaluating models...\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Training Gradient Boosting...\n",
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.5200\n",
      "ROC-AUC: 0.5919\n",
      "CV ROC-AUC: 0.5250\n",
      "Precision: 0.6667\n",
      "Recall: 0.4000\n",
      "F1 Score: 0.5000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[28 12]\n",
      " [36 24]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.70      0.54        40\n",
      "           1       0.67      0.40      0.50        60\n",
      "\n",
      "    accuracy                           0.52       100\n",
      "   macro avg       0.55      0.55      0.52       100\n",
      "weighted avg       0.57      0.52      0.52       100\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.6200\n",
      "ROC-AUC: 0.5929\n",
      "CV ROC-AUC: 0.4877\n",
      "Precision: 0.7115\n",
      "Recall: 0.6167\n",
      "F1 Score: 0.6607\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25 15]\n",
      " [23 37]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.62      0.57        40\n",
      "           1       0.71      0.62      0.66        60\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.62      0.62      0.61       100\n",
      "weighted avg       0.64      0.62      0.62       100\n",
      "\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "Accuracy: 0.6100\n",
      "ROC-AUC: 0.6042\n",
      "CV ROC-AUC: 0.5011\n",
      "Precision: 0.6364\n",
      "Recall: 0.8167\n",
      "F1 Score: 0.7153\n",
      "\n",
      "Confusion Matrix:\n",
      "[[12 28]\n",
      " [11 49]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.30      0.38        40\n",
      "           1       0.64      0.82      0.72        60\n",
      "\n",
      "    accuracy                           0.61       100\n",
      "   macro avg       0.58      0.56      0.55       100\n",
      "weighted avg       0.59      0.61      0.58       100\n",
      "\n",
      "\n",
      "Tuning Gradient Boosting hyperparameters...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 50, 'subsample': 1.0}\n",
      "\n",
      "=== Tuned Gradient Boosting ===\n",
      "ROC-AUC: 0.6190\n",
      "Accuracy: 0.5800\n",
      "Precision: 0.5918\n",
      "Recall: 0.9667\n",
      "F1 Score: 0.7342\n",
      "\n",
      "Analyzing feature importance...\n",
      "\n",
      "Saving best model...\n",
      "\n",
      "=== Model Training Complete ===\n",
      "Best model (Tuned Gradient Boosting) saved to best_loan_model.pkl\n",
      "\n",
      "Analyzing decision thresholds...\n",
      "\n",
      "Optimal threshold: 0.3746\n",
      "Max F1 Score: 0.7500\n",
      "\n",
      "Final evaluation with optimal threshold...\n",
      "\n",
      "=== Final Model with Optimal Threshold ===\n",
      "Accuracy: 0.6000\n",
      "Precision: 0.6000\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.7500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0 40]\n",
      " [ 0 60]]\n"
     ]
    }
   ],
   "source": [
    "# loan_prediction_analysis_improved.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV, \n",
    "                                   cross_val_score, StratifiedKFold)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                             GradientBoostingClassifier)\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, \n",
    "                           classification_report, roc_auc_score, \n",
    "                           RocCurveDisplay, precision_score, \n",
    "                           recall_score, f1_score, precision_recall_curve)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ====================== 1. Data Loading & Initial Inspection ======================\n",
    "print(\"Loading and inspecting data...\")\n",
    "df = pd.read_csv('loan_data.csv')\n",
    "\n",
    "print(\"\\n=== First 5 Rows ===\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n=== Dataset Info ===\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ====================== 2. Data Cleaning ======================\n",
    "print(\"\\nCleaning data...\")\n",
    "# Drop irrelevant columns\n",
    "df.drop(['Loan_ID', 'effective_date', 'due_date', 'paid_off_time'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values - we'll remove past_due_days entirely later\n",
    "df['past_due_days'] = df['past_due_days'].fillna(0)\n",
    "\n",
    "# ====================== 3. Feature Engineering ======================\n",
    "print(\"\\nEngineering features...\")\n",
    "# Target encoding\n",
    "df['loan_status'] = df['loan_status'].map({\n",
    "    'PAIDOFF': 1,\n",
    "    'COLLECTION': 0,\n",
    "    'COLLECTION_PAIDOFF': 0\n",
    "})\n",
    "\n",
    "# Categorical encoding\n",
    "df['Gender'] = df['Gender'].map({'male': 0, 'female': 1})\n",
    "education_map = {\n",
    "    'High_School_or_Below': 0, \n",
    "    'College': 1, \n",
    "    'Bachelor': 2, \n",
    "    'Master_or_Above': 3\n",
    "}\n",
    "df['education'] = df['education'].map(education_map)\n",
    "\n",
    "# ====================== 4. Correlation Analysis ======================\n",
    "print(\"\\nAnalyzing correlations...\")\n",
    "correlation_matrix = df.corr()\n",
    "print(\"\\n=== Correlation with loan_status ===\")\n",
    "print(correlation_matrix['loan_status'].sort_values(ascending=False))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.close()  # Close plot to prevent display in notebook environments\n",
    "\n",
    "# ====================== 5. Data Preparation ======================\n",
    "print(\"\\nPreparing data for modeling...\")\n",
    "X = df.drop(['loan_status', 'past_due_days'], axis=1)  # Remove potential leaky feature\n",
    "y = df['loan_status']\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "num_cols = ['Principal', 'terms', 'age']\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(\"\\nClass weights:\", class_weight_dict)\n",
    "\n",
    "# ====================== 6. Feature Selection ======================\n",
    "print(\"\\nSelecting best features...\")\n",
    "selector = SelectKBest(f_classif, k='all')  # Evaluate all features\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get feature scores\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Score': selector.scores_\n",
    "}).sort_values('Score', ascending=False)\n",
    "\n",
    "print(\"\\nFeature importance scores:\")\n",
    "print(feature_scores)\n",
    "\n",
    "# Select top features (adjust k as needed)\n",
    "top_k = 4  # Using all features for now since we only have 5\n",
    "X_train_selected = X_train\n",
    "X_test_selected = X_test\n",
    "\n",
    "# ====================== 7. Model Training & Evaluation ======================\n",
    "print(\"\\nTraining and evaluating models...\")\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        max_iter=1000, \n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    y_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results[name] = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
    "        \"classification_report\": classification_report(y_test, y_pred),\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(\n",
    "        model, X_train_selected, y_train, \n",
    "        cv=cv, scoring='roc_auc'\n",
    "    )\n",
    "    results[name]['cv_roc_auc'] = np.mean(cv_scores)\n",
    "    \n",
    "    # Plot ROC Curve\n",
    "    RocCurveDisplay.from_estimator(model, X_test_selected, y_test)\n",
    "    plt.title(f'ROC Curve - {name}')\n",
    "    plt.savefig(f'roc_curve_{name.lower().replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - {name}')\n",
    "    plt.savefig(f'pr_curve_{name.lower().replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"CV ROC-AUC: {metrics['cv_roc_auc']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(metrics['confusion_matrix'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(metrics['classification_report'])\n",
    "\n",
    "# ====================== 8. Hyperparameter Tuning ======================\n",
    "print(\"\\nTuning Gradient Boosting hyperparameters...\")\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "best_gb = grid_search.best_estimator_\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate best model\n",
    "y_pred = best_gb.predict(X_test_selected)\n",
    "y_proba = best_gb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "print(\"\\n=== Tuned Gradient Boosting ===\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# ====================== 9. Feature Importance Analysis ======================\n",
    "print(\"\\nAnalyzing feature importance...\")\n",
    "# For tree-based models\n",
    "for name in [\"Random Forest\", \"Gradient Boosting\", \"Tuned Gradient Boosting\"]:\n",
    "    model = results[name]['model'] if name != \"Tuned Gradient Boosting\" else best_gb\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        plt.title(f\"Feature Importance - {name}\")\n",
    "        plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "        plt.yticks(range(len(indices)), [X.columns[i] for i in indices])\n",
    "        plt.xlabel('Relative Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'feature_importance_{name.lower().replace(\" \", \"_\")}.png')\n",
    "        plt.close()\n",
    "\n",
    "# ====================== 10. Save Best Model ======================\n",
    "print(\"\\nSaving best model...\")\n",
    "best_model = best_gb  # Using the tuned Gradient Boosting model\n",
    "\n",
    "with open('best_loan_model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': best_model,\n",
    "        'scaler': scaler,\n",
    "        'education_map': education_map,\n",
    "        'features': list(X.columns),\n",
    "        'num_cols': num_cols\n",
    "    }, f)\n",
    "\n",
    "print(\"\\n=== Model Training Complete ===\")\n",
    "print(\"Best model (Tuned Gradient Boosting) saved to best_loan_model.pkl\")\n",
    "\n",
    "# ====================== 11. Threshold Analysis ======================\n",
    "print(\"\\nAnalyzing decision thresholds...\")\n",
    "y_proba = best_gb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Find threshold that maximizes F1 score\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"\\nOptimal threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Max F1 Score: {f1_scores[optimal_idx]:.4f}\")\n",
    "\n",
    "# Plot precision-recall vs threshold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, precision[:-1], label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall')\n",
    "plt.plot(thresholds, f1_scores[:-1], label='F1 Score')\n",
    "plt.axvline(x=optimal_threshold, color='r', linestyle='--', label='Optimal Threshold')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall, and F1 Score by Threshold')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('optimal_threshold.png')\n",
    "plt.close()\n",
    "\n",
    "# ====================== 12. Final Model Evaluation with Optimal Threshold ======================\n",
    "print(\"\\nFinal evaluation with optimal threshold...\")\n",
    "y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"\\n=== Final Model with Optimal Threshold ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_optimal):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_optimal):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_optimal):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_optimal):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc40d3f-701b-4b27-8175-775a3710f332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
